{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10693022,"sourceType":"datasetVersion","datasetId":6625612}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install langchain_openai langchain langchain_community faiss-gpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T19:34:42.437204Z","iopub.execute_input":"2025-03-14T19:34:42.437657Z","iopub.status.idle":"2025-03-14T19:34:59.611798Z","shell.execute_reply.started":"2025-03-14T19:34:42.437611Z","shell.execute_reply":"2025-03-14T19:34:59.610737Z"}},"outputs":[{"name":"stdout","text":"Collecting langchain_openai\n  Downloading langchain_openai-0.3.8-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.12)\nCollecting langchain_community\n  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\nCollecting faiss-gpu\n  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting langchain-core<1.0.0,>=0.3.42 (from langchain_openai)\n  Downloading langchain_core-0.3.45-py3-none-any.whl.metadata (5.9 kB)\nCollecting openai<2.0.0,>=1.58.1 (from langchain_openai)\n  Downloading openai-1.66.3-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.8.0)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.11)\nCollecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\nRequirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\nRequirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.11.0a1)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\nCollecting langchain\n  Downloading langchain-0.3.20-py3-none-any.whl.metadata (7.7 kB)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nCollecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain)\n  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (2.4.1)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.28.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.28.0)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (1.2.2)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.42->langchain_openai) (3.0.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.22.4->langchain) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.22.4->langchain) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.22.4->langchain) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2,>=1.22.4->langchain) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2,>=1.22.4->langchain) (2024.2.0)\nDownloading langchain_openai-0.3.8-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain-0.3.20-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\nDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading langchain_core-0.3.45-py3-none-any.whl (415 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.9/415.9 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\nDownloading openai-1.66.3-py3-none-any.whl (567 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m567.4/567.4 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\nDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\nInstalling collected packages: faiss-gpu, python-dotenv, httpx-sse, async-timeout, pydantic-settings, openai, langchain-core, langchain-text-splitters, langchain_openai, langchain, langchain_community\n  Attempting uninstall: async-timeout\n    Found existing installation: async-timeout 5.0.1\n    Uninstalling async-timeout-5.0.1:\n      Successfully uninstalled async-timeout-5.0.1\n  Attempting uninstall: openai\n    Found existing installation: openai 1.57.4\n    Uninstalling openai-1.57.4:\n      Successfully uninstalled openai-1.57.4\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.25\n    Uninstalling langchain-core-0.3.25:\n      Successfully uninstalled langchain-core-0.3.25\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.3\n    Uninstalling langchain-text-splitters-0.3.3:\n      Successfully uninstalled langchain-text-splitters-0.3.3\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.12\n    Uninstalling langchain-0.3.12:\n      Successfully uninstalled langchain-0.3.12\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed async-timeout-4.0.3 faiss-gpu-1.7.2 httpx-sse-0.4.0 langchain-0.3.20 langchain-core-0.3.45 langchain-text-splitters-0.3.6 langchain_community-0.3.19 langchain_openai-0.3.8 openai-1.66.3 pydantic-settings-2.8.1 python-dotenv-1.0.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport re\nimport bs4\nfrom uuid import uuid4\nfrom langchain import hub\nfrom langchain_community.document_loaders import PyPDFLoader, TextLoader, WebBaseLoader\nfrom langchain_community.vectorstores import FAISS\nfrom langchain.chains import RetrievalQA\nfrom langchain.schema import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom langchain.agents import AgentExecutor, create_react_agent\nfrom langchain.memory import ChatMessageHistory\nfrom langchain_core.tools import Tool\nfrom langchain_core.runnables.history import RunnableWithMessageHistory\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nprint('Import completed')\n\n# Set up API key\nOPENAI_API_KEY = \"sk...\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-14T19:35:02.084904Z","iopub.execute_input":"2025-03-14T19:35:02.085290Z","iopub.status.idle":"2025-03-14T19:35:05.579856Z","shell.execute_reply.started":"2025-03-14T19:35:02.085259Z","shell.execute_reply":"2025-03-14T19:35:05.578709Z"}},"outputs":[{"name":"stdout","text":"Import completed\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def defined_llm(OPENAI_API_KEY):\n    SESSION_ID = str(uuid4())\n    print(f\"Session ID: {SESSION_ID}\")\n    \n    llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-4-turbo\")\n    embedding_provider = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=800,\n        chunk_overlap=150,\n        separators=[r'\\n\\s*•', r'\\n\\d+\\.', r'\\n\\*', '\\n\\n'],\n        add_start_index=True\n    )\n    \n    vectorstore = FAISS.from_texts(\n        texts=[\"Math Knowledge Base Initialized\"], \n        embedding=embedding_provider,\n        metadatas=[{\"source\": \"system-init\"}]\n    )\n    retriever = vectorstore.as_retriever(\n        search_type=\"mmr\",\n        search_kwargs={\n            \"k\": 5,\n            \"score_threshold\": 0.7,\n            \"lambda_mult\": 0.5\n        }\n)\n\n    def format_docs(docs):\n        formatted = []\n        for i, doc in enumerate(docs):\n            if hasattr(doc, 'metadata'):\n                source_type = doc.metadata.get('source_type', 'unknown')\n                source = doc.metadata.get('source_path', doc.metadata.get('source_url', 'unknown'))\n                content = doc.page_content\n            else:\n                source_type = \"unknown\"\n                source = \"unknown\"\n                content = str(doc)\n                \n            formatted.append(\n                f\"📚 Source {i+1} ({source_type}): {source}\\n\"\n                f\"{content[:500]}...\"\n            )\n        return \"\\n\\n\".join(formatted)\n\n    chat_prompt = \"\"\"You are a mathematical AI assistant. If it is a math related problem, use this response format:\n\n    **Problem Analysis**\n    Recognize the mathematical field, identify relevant subfields. Analyze the promblem\n    \n    **Key Formulas**\n    All formulas that can be used to solve the problem\n    - Formula 1\n    - Formula 2\n    ...\n    \n    **Solution Steps**\n    Detail explanation for each step\n    1. step1\n    2. step2\n    ...\n    \n    **Self-Check**\n    Check the intuition, formulas, solution steps. Try to prove your result is wrong. If the result is wrong, redo the problem. If the result is correct, prove it again.\n    - Check 1\n    - Check 2\n    ...\n    \n    **Final Answer**\n    [Clear conclusion with boxed answer]\"\"\"\n    \n    prompt = ChatPromptTemplate.from_messages([\n        (\"system\", chat_prompt),\n        MessagesPlaceholder(\"chat_history\"),\n        (\"human\", \"Context:\\n{context}\\n\\nQuestion: {input}\"),\n    ])\n\n    # Core processing chain\n    rag_chain = (\n        RunnablePassthrough.assign(\n            context=lambda x: format_docs(x[\"context\"]),\n            chat_history=lambda x: x[\"chat_history\"]\n        )\n        | prompt\n        | llm\n        | StrOutputParser()\n    )\n\n    contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question:\n    1. DO NOT modify or rephrase the original question\n    2. Instead, add any relevant background information from the chat history as a prefix\n    3. Format the output as:\n       [Background Info (if any)]\n       Original Question: <exact original question>\"\"\"\n    \n    contextualize_q_prompt = ChatPromptTemplate.from_messages([\n        (\"system\", contextualize_q_system_prompt),\n        MessagesPlaceholder(\"chat_history\"),\n        (\"human\", \"{input}\"),\n    ])\n\n    def process_query(input_text, chat_history):\n        standalone_chain = contextualize_q_prompt | llm | StrOutputParser()\n        standalone_question = standalone_chain.invoke({\n            \"chat_history\": chat_history,\n            \"input\": input_text\n        })\n        \n        def debug_retrieval(query, retriever, top_k=3):\n            docs = retriever.invoke(query)\n            print(\"\\n🔍 Retrieved Context Preview:\")\n            for i, doc in enumerate(docs[:top_k]):\n                print(f\"\\n📄 Document {i+1}:\")\n                print(f\"   Source: {doc.metadata.get('source_url', doc.metadata.get('source_path', 'unknown'))}\")\n                print(f\"   Content: {doc.page_content[:300]}...\")\n            return docs\n        relevant_docs = debug_retrieval(standalone_question, retriever)\n        context = format_docs(relevant_docs)\n        \n        response = rag_chain.invoke({\n            \"input\": input_text,\n            \"context\": context,\n            \"chat_history\": chat_history\n        })\n\n        check_prompt = f\"\"\"The previous solution for this question is wrong, check and do it again. \n\n        Question: {input_text}\n\n        Previous solution:\n        {response}\n        \"\"\"\n        # Self-check verification\n        # check_prompt = f\"\"\"Verify this solution contains:\n        # 1. Make sure the logic is correct. Check each step, including the method, formulas, etc.\n        # 2. Self-verify the solution by trying to disprove it.\n        # 3. If errors are found, correct them. Otherwise, return 'VERIFIED'.\n\n        # If any issues are found, provide the correction.\n        # If no issues are found, respond with \"VERIFIED\" and briefly explain why.\n\n        # Question: {input_text}\n\n        # Solution to verify:\n        # {response}\n        # \"\"\"\n        verification = rag_chain.invoke({\n            \"input\": check_prompt,\n            \"context\": context,\n            \"chat_history\": chat_history\n        })\n\n        \n        return f\"{response}\\n\\n**Verification:**\\n{verification}\"\n\n    # Memory\n    store = {}\n    def get_memory(session_id: str) -> ChatMessageHistory:\n        if session_id not in store:\n            store[session_id] = ChatMessageHistory(max_messages=20)\n        return store[session_id]\n\n    chat_agent = RunnableWithMessageHistory(\n        RunnablePassthrough.assign(\n            response=lambda x: process_query(x[\"input\"], x[\"chat_history\"])\n        ),\n        get_memory,\n        input_messages_key=\"input\",\n        history_messages_key=\"chat_history\",\n    )\n    \n    def process_file(file_path):\n        try:\n            if not os.path.exists(file_path):\n                raise FileNotFoundError(f\"File not found: {file_path}\")\n            \n            loader = PyPDFLoader(file_path) if file_path.endswith('.pdf') else TextLoader(file_path)\n            docs = loader.load()\n            splits = text_splitter.split_documents(docs)\n            \n            # Add metadata with content type detection\n            for split in splits:\n                split.metadata.update({\n                    \"source_type\": \"file\",\n                    \"source_path\": file_path,\n                    \"content_type\": self_detect_content_type(split.page_content)  # Added content type\n                })\n            \n            vectorstore.add_documents(splits)\n            print(f\"\\nAI: Added {len(splits)} chunks from {os.path.basename(file_path)}\")\n            return True\n        except Exception as e:\n            print(f\"\\nAI: Error processing {file_path}: {str(e)}\")\n            return False\n    \n    def process_web_content(url):\n        try:\n            loader = WebBaseLoader(\n                web_paths=[url],\n                bs_kwargs=dict(\n                    parse_only=bs4.SoupStrainer(\n                        # Universal content detection\n                        ['article', 'main', 'div', 'section', 'content'],\n                        class_=lambda value: value and any(\n                            kw in value.lower()\n                            for kw in ['content', 'article', 'main', 'body', 'text']\n                        )\n                    )\n                )\n            )\n            docs = loader.load()\n            splits = text_splitter.split_documents(docs)\n            \n            for split in splits:\n                split.metadata.update({\n                    \"source_type\": \"web\",\n                    \"source_url\": url,\n                    \"content_type\": self_detect_content_type(split.page_content)\n                })\n            \n            vectorstore.add_documents(splits)\n            print(f\"\\nAI: Added {len(splits)} chunks from {url}\")\n            return True\n        except Exception as e:\n            print(f\"\\nAI: Error processing {url}: {str(e)}\")\n            return False\n\n    def self_detect_content_type(text):\n        math_keywords = ['theorem', 'formula', 'equation', 'proof', 'lemma']\n        if any(kw in text.lower() for kw in math_keywords):\n            return \"math\"\n        return \"general\"\n\n    # Interactive loop\n    print(\"Math Expert System - Type 'exit' to quit\")\n    print(\"Input formats:\")\n    print(\"- RAG_file_path=\\\"/path/to/file.pdf\\\" https://example.com Your question\")\n    print(\"- Include math formulas using $...$ notation\")\n    \n    url_pattern = re.compile(\n        r'(?:http|ftp)s?://(?:[A-Z0-9-]+\\.)+[A-Z]{2,}(?::\\d+)?(?:/[\\w\\-./?%&=]*)?', \n        re.IGNORECASE\n    )\n    \n    while True:\n        try:\n            user_input = input(\"\\nYou: \").strip()\n            if user_input.lower() in ['exit', 'quit']:\n                print(\"Goodbye!\")\n                break\n\n            # Process file paths\n            file_paths = re.findall(r'RAG_file_path=\"([^\"]+)\"', user_input)\n            for fp in file_paths:\n                if process_file(fp):\n                    user_input = user_input.replace(f'RAG_file_path=\"{fp}\"', '').strip()\n\n            # Process URLs\n            urls = re.findall(r'https?://\\S+', user_input)\n            for url in urls:\n                if process_web_content(url):\n                    user_input = user_input.replace(url, '').strip()\n\n            # Process remaining input\n            user_input = re.sub(r'\\s+', ' ', user_input).strip()\n            if not user_input:\n                continue\n                \n            response = chat_agent.invoke(\n                {\"input\": user_input},\n                {\"configurable\": {\"session_id\": SESSION_ID}}\n            )\n            print(f\"\\nAI: {response['response']}\")\n            \n        except Exception as e:\n            print(f\"Error: {str(e)}\")\n            continue\n    \n    return chat_agent\n\ndefined_llm(OPENAI_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T20:09:23.902694Z","iopub.execute_input":"2025-03-14T20:09:23.903099Z","iopub.status.idle":"2025-03-14T20:10:57.588326Z","shell.execute_reply.started":"2025-03-14T20:09:23.903049Z","shell.execute_reply":"2025-03-14T20:10:57.587391Z"}},"outputs":[{"name":"stdout","text":"Session ID: d9924e10-bd2f-4735-947d-db043eff0981\nMath Expert System - Type 'exit' to quit\nInput formats:\n- RAG_file_path=\"/path/to/file.pdf\" https://example.com Your question\n- Include math formulas using $...$ notation\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nYou:  https://en.wikipedia.org/wiki/Modular_arithmetic 20 bees are sitting on 20 daisies, one bee on each flower. The flowers are arranged in a ring. From time to time 2 bees simultaneously fly  in opposite directions (clockwise and counterclockwise), each to its neighboring flower. Can all bees gather on the same daisy at some point? Will your answer be the same for 19 daisies and 19 bees?\n"},{"name":"stdout","text":"\nAI: Added 29 chunks from https://en.wikipedia.org/wiki/Modular_arithmetic\n\n🔍 Retrieved Context Preview:\n\n📄 Document 1:\n   Source: https://en.wikipedia.org/wiki/Modular_arithmetic\n   Content: a\n¯\n\n\n\nm\n\n\n\n\n\nb\n¯\n\n\n\nm\n\n\n=\n\n\n\n\n(\na\nb\n)\n\n¯\n\n\n\nm\n\n\n.\n\n\n{\\displaystyle {\\overline {a}}_{m}{\\overline {b}}_{m}={\\overline {(ab)}}_{m}.}\n\n\nThe properties given before imply that, with these operations, \n\n\n\n\nZ\n\n\n/\n\nm\n\nZ\n\n\n\n{\\displaystyle \\mathbb {Z} /m\\mathbb {Z} }\n\n is a commutative ring. For example, in...\n\n📄 Document 2:\n   Source: unknown\n   Content: Math Knowledge Base Initialized...\n\n📄 Document 3:\n   Source: https://en.wikipedia.org/wiki/Modular_arithmetic\n   Content: ^ \"Euler's sum of powers conjecture\". rosettacode.org. Archived from the original on 2023-03-26. Retrieved 2020-11-11.\n\n^ Garey, M. R.; Johnson, D. S. (1979). Computers and Intractability, a Guide to the Theory of NP-Completeness. W. H. Freeman. ISBN 0716710447....\n\nAI: **Problem Analysis**\nThis problem involves understanding a dynamic system with motion constrained to circular/periodic boundary conditions. Specifically, it's based on whether certain configurations (all bees on a single daisy) can be achieved given specific movement constraints and starting conditions. This is essentially a problem of symmetrical movement on a ring.\n\n**Key Formulas**\nThere isn't a direct formula, but we can use combinatorial and symmetry principles to determine possible configurations.\n\n**Solution Steps**\n1. **Analyzing Movement and Configuration for 20 Bees and 20 Daisies:**\n   - Each bee moves to its immediate neighboring daisy either clockwise or counterclockwise.\n   - The ring has an even number of daisies (20). This means that at each step, bees effectively swap positions symmetrically.\n   - After each move, bees that moved clockwise will occupy daisies at even indices (if started from odd), and vice versa for counter-clockwise moving bees. The starting condition has each bee on a distinct flower, so initial indices are evenly distributed.\n\n2. **Considering Meeting Conditions:**\n   - Since every bee moves one daisy per step in either a clockwise or counterclockwise direction, to gather all bees on the same daisy, they would all need to converge in one of the movements at the same indexed position.\n   - If bees can only move to adjacent daisies, the only time all bees distribute on either even or odd indexed daisies is when there is a constant even or odd divergence which here, given complete symmetry and the even number, is the same in magnitude but opposite in direction.\n   - The periodic nature of their movement (circular constraint) with everyone moving per specific rules (to the next daisy in exactly opposite directions) conserves their staggered distribution.\n\n3. **Conclusion for 20 Bees and 20 Daisies:**\n   - Given the evenly distributed start and the specific alternating constraints of movement (clockwise and counterclockwise to direct neighbors), bees will always occupy alternating daisies. They will never all meet on a single daisy.\n\n4. **Analysis for 19 Bees and 19 Daisies:**\n   - With 19 (an odd number), the bees again move to adjacent daisies. Still, the odd count introduces a non-symmetrical dis-placement over steps when cycling through positions.\n   - The initial condition and the movement nature still follow a staggered odd/even sequence, but the number being odd adds a non-matching step in the sequence due to the periodic boundary (the ring structure) eventually aligning them differently.\n   - A similar argument from the 20-bee scenario holds initially; however, eventually, since the configuration phases through a different sequence each time due to the odd count, they may end up on the same daisy after a specific number of moves that align similarly.\n\n**Self-Check**\n- For the even case (20 bees), positions alternate between odd and even indexed daisies, never meeting on the same due to continuous symmetry.\n- For the odd case (19 bees), the disruption from the odd number theoretically allows positional convergence, although it relies on periodic alignments over multiple moves.\n\n**Final Answer**\n- For 20 bees on 20 daisies: **No**, the bees will not gather on the same daisy.\n- For 19 bees on 19 daisies: **Potentially yes**, depending on the number of movements and detailed configuration analysis, but it's more feasible here than in the even-count scenario.\n\n**Verification:**\n**Problem Analysis**\nThis problem explores the behavior of bees on a circular arrangement of daisies with specific movement rules. We need to determine if there is a scenario where all bees can end up on the same daisy. This problem can be associated with cyclic permutations and partitioning of circular sequences in combinatorics.\n\n**Key Formulas**\n- No specific formulas, but principles of symmetry and parity in circular structures will be useful.\n- Considering the movements in congruent modulo operations (especially for the circular nature of the arrangement) is also pertinent.\n\n**Solution Steps**\n1. **Setup and Assumptions:**\n   - There are 20 bees on 20 daisies arranged in a circle, with one bee per daisy.\n   - Bees can move either clockwise or counterclockwise to only adjacent daisies.\n\n2. **Evaluating Movement Constraints:**\n   - Each bee moving oppositely means that after each move, given the problem constraints (two bees move per cycle, one clockwise and the other counterclockwise), the relative positions remain symmetrical about the circular array.\n   - This symmetry and the preservation of parity (even-indexed move to other even-indexed or odd-indexed and vice versa) imply that at each move, the bees either occupy two specific positions that are directly opposite each other on the circle or return to initial positions after complete rotations around the circle.\n\n3. **Analyzing Convergence for 20 Bees:**\n   - Given an even number of bees (20), the bees will maintain their symmetrical distribution as each bee moves and their movements are evenly balanced around the circle.\n   - Symmetrical distribution implies that one half of the bees will be on even indices and other on odd indices, swapping places as they move but never converging all at one point.\n\n4. **Considering 19 Bees and 19 Daisies Scenario:**\n   - Here, the number of bees and daisies is odd, introducing a potentially disruptive shift in symmetry each movement cycle.\n   - Each bee moves to adjacent positions; however, due to the odd number, there isn't a perfectly symmetrical counterpart for each bee.\n   - This disruption means that while the usual symmetry might not hold, the periodic nature of the circle and the staggered steps introduced by the imparity (odd count) could theoretically lead to a situation where all bees converge over multiple comprehensive cycles of movement. It is not straightforward and requires mathematical exploration or simulation to confirm convergence points.\n\n**Self-Check**\n- Confirmed the initial assumptions about parities and symmetrical distribution.\n- Checked the logic behind movement disruption caused by the odd versus even count disparity.\n- Reflection on problem stating and specification that the movement conditions strictly adhere to neighboring transfers.\n\n**Final Answer**\n- For 20 bees on 20 daisies: **No**, the bees will not gather on the same daisy, due to the even distribution and preserved cycle parity.\n- For 19 bees on 19 daisies: **Potentially yes**, but it is highly contingent on specific movement sequences and would likely require extensive iterations to achieve, assuming it's feasible based on movement rules.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nYou:  exit\n"},{"name":"stdout","text":"Goodbye!\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n  chat_history: RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n}), kwargs={}, config={'run_name': 'insert_history'}, config_factories=[])\n| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]), kwargs={}, config={}, config_factories=[], get_session_history=<function defined_llm.<locals>.get_memory at 0x7bab0d01b6d0>, input_messages_key='input', history_messages_key='chat_history', history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":" 20 bees are sitting on 20 daisies, one bee on each flower. The flowers are arranged in a ring. From time to time 2 bees simultaneously fly  in opposite directions (clockwise and counterclockwise), each to its neighboring flower. Can all bees gather on the same daisy at some point? Will your answer be the same for 19 daisies and 19 bees?","metadata":{}},{"cell_type":"code","source":"#Original\n# SETUPs\nchat_prompt = \"\"\"You are a mathematical AI assistant. If it is a math related problem, use this response format:\n\n**Problem Analysis**\nAnalyze the promblem\n\n**Key Formulas**\nAll formulas that can be used to solve the problem\n- Formula 1\n- Formula 2\n...\n\n**Solution Steps**\nDetail explanation for each step\n1. step1\n2. step2\n...\n\n**Self-Check**\nCheck the intuition, formulas, solution steps. Try to prove your result is wrong. If the result is wrong, redo the problem. If the result is correct, prove it again.\n- Check 1\n- Check 2\n...\n\n**Final Answer**\n[Clear conclusion with boxed answer]\"\"\"\n\n# Load the agent prompt from LagnSmith\nagent_prompt = hub.pull(\"hwchase17/react-chat\") # a common agent, should consider create one for this specific task\n\nRAG_file_path = '/kaggle/input/probability-textbook/Probability.pdf'\n\ndef defined_llm(OPENAI_API_KEY, chat_prompt=chat_prompt):\n    SESSION_ID = str(uuid4())\n    print(f\"Session ID: {SESSION_ID}\")\n    \n    llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-4-turbo\")\n    embedding_provider = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=800,\n        chunk_overlap=150,\n        separators=['\\n\\n'],\n        add_start_index=True\n    )\n    \n    vectorstore = FAISS.from_texts(\n        texts=[\"Math Knowledge Base Initialized\"], \n        embedding=embedding_provider,\n        metadatas=[{\"source\": \"system-init\"}]\n    )\n    retriever = vectorstore.as_retriever(\n        search_type=\"mmr\",\n        search_kwargs={\n            \"k\": 5,\n            \"score_threshold\": 0.7,\n            \"lambda_mult\": 0.5\n        }\n)\n\n    def format_docs(docs):\n        formatted = []\n        for i, doc in enumerate(docs):\n            # Handle Document objects\n            if hasattr(doc, 'metadata'):\n                source_type = doc.metadata.get('source_type', 'unknown')\n                source = doc.metadata.get('source_path', doc.metadata.get('source_url', 'unknown'))\n                content = doc.page_content\n            # Handle strings (fallback)\n            else:\n                source_type = \"unknown\"\n                source = \"unknown\"\n                content = str(doc)\n                \n            formatted.append(\n                f\"📚 Source {i+1} ({source_type}): {source}\\n\"\n                f\"{content[:500]}...\"\n            )\n        return \"\\n\\n\".join(formatted)\n\n\n    prompt = ChatPromptTemplate.from_messages([\n        (\"system\", chat_prompt),\n        MessagesPlaceholder(\"chat_history\"),\n        (\"human\", \"Context:\\n{context}\\n\\nQuestion: {input}\"),\n    ])\n\n    # Core processing chain\n    rag_chain = (\n        RunnablePassthrough.assign(\n            context=lambda x: format_docs(x[\"context\"]),\n            chat_history=lambda x: x[\"chat_history\"]\n        )\n        | prompt\n        | llm\n        | StrOutputParser()\n    )\n\n    contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question:\n    1. DO NOT modify or rephrase the original question\n    2. Instead, add any relevant background information from the chat history as a prefix\n    3. Format the output as:\n       [Background Info (if any)]\n       Original Question: <exact original question>\"\"\"\n    \n    contextualize_q_prompt = ChatPromptTemplate.from_messages([\n        (\"system\", contextualize_q_system_prompt),\n        MessagesPlaceholder(\"chat_history\"),\n        (\"human\", \"{input}\"),\n    ])\n\n    def process_query(input_text, chat_history):\n        standalone_chain = contextualize_q_prompt | llm | StrOutputParser()\n        standalone_question = standalone_chain.invoke({\n            \"chat_history\": chat_history,\n            \"input\": input_text\n        })\n\n        def debug_retrieval(query, retriever, top_k=3):\n            docs = retriever.invoke(query)\n            print(\"\\n🔍 Retrieved Context Preview:\")\n            for i, doc in enumerate(docs[:top_k]):\n                print(f\"\\n📄 Document {i+1}:\")\n                print(f\"   Source: {doc.metadata.get('source_url', doc.metadata.get('source_path', 'unknown'))}\")\n                print(f\"   Content: {doc.page_content[:300]}...\")\n            return docs\n        relevant_docs = debug_retrieval(standalone_question, retriever)\n        context = format_docs(relevant_docs)\n        \n        response = rag_chain.invoke({\n            \"input\": input_text,\n            \"context\": context,\n            \"chat_history\": chat_history\n        })\n       \n        # Self-check verification\n        check_prompt = f\"\"\"Verify this solution contains:\n        1. Make sure the logic is correct. Check the method, formulas, each step.\n        2. Try to prove the response is incorrect. If it is incorrect, follow the logic and redo the problem.\n        3. Prove the response is correct.\n\n        If any issues are found, provide the correction.\n        If no issues are found, respond with \"VERIFIED\" and briefly explain why.\n        \n        Solution to verify:\n        {response}\n        \n        Missing/incorrect components:\"\"\"\n        \n        verification = rag_chain.invoke({\n            \"input\": check_prompt,\n            \"context\": context,\n            \"chat_history\": chat_history\n        })\n        \n        # If verification finds issues, get corrected solution\n        if \"VERIFIED\" not in verification:\n            corrected = rag_chain.invoke({\n                \"input\": f\"\"\"The previous solution had issues. Please provide a corrected solution that addresses these verification issues:{verification}\n                Original question: {input_text}\"\"\",\n                \"context\": context,\n                \"chat_history\": chat_history\n            })\n            return f\"{response}\\n\\n**Original Verification Feedback:**\\n{verification}\\n\\n**Corrected Response:**\\n{corrected}\"\n        \n        return f\"{response}\\n\\n**Verification:**\\n{verification}\"\n\n    # Memory\n    store = {}\n    def get_memory(session_id: str) -> ChatMessageHistory:\n        if session_id not in store:\n            store[session_id] = ChatMessageHistory(max_messages=20)\n        return store[session_id]\n\n    chat_agent = RunnableWithMessageHistory(\n        RunnablePassthrough.assign(\n            response=lambda x: process_query(x[\"input\"], x[\"chat_history\"])\n        ),\n        get_memory,\n        input_messages_key=\"input\",\n        history_messages_key=\"chat_history\",\n    )\n\n    def process_web_content(url):\n        try:\n            loader = WebBaseLoader(\n                web_paths=[url],\n                bs_kwargs=dict(\n                    parse_only=bs4.SoupStrainer(\n                        # Universal content detection\n                        ['article', 'main', 'div', 'section', 'content'],\n                        class_=lambda value: value and any(\n                            kw in value.lower()\n                            for kw in ['content', 'article', 'main', 'body', 'text']\n                        )\n                    )\n                )\n            )\n            docs = loader.load()\n            splits = text_splitter.split_documents(docs)\n            \n            for split in splits:\n                split.metadata.update({\n                    \"source_type\": \"web\",\n                    \"source_url\": url,\n                    \"content_type\": self_detect_content_type(split.page_content)\n                })\n            \n            vectorstore.add_documents(splits)\n            print(f\"\\nAI: Added {len(splits)} chunks from {url}\")\n            return True\n        except Exception as e:\n            print(f\"\\nAI: Error processing {url}: {str(e)}\")\n            return False\n\n    def self_detect_content_type(text):\n        math_keywords = ['theorem', 'formula', 'equation', 'proof', 'lemma']\n        if any(kw in text.lower() for kw in math_keywords):\n            return \"math\"\n        return \"general\"\n\n    # Interactive loop\n    print(\"Math Expert System - Type 'exit' to quit\")\n    print(\"Input formats:\")\n    print(\"- RAG_file_path=\\\"/path/to/file.pdf\\\" https://example.com Your question\")\n    print(\"- Include math formulas using $...$ notation\")\n    \n    url_pattern = re.compile(\n        r'(?:http|ftp)s?://(?:[A-Z0-9-]+\\.)+[A-Z]{2,}(?::\\d+)?(?:/[\\w\\-./?%&=]*)?', \n        re.IGNORECASE\n    )\n    \n    while True:\n        try:\n            user_input = input(\"\\nYou: \").strip()\n            if user_input.lower() in ['exit', 'quit']:\n                print(\"Goodbye!\")\n                break\n\n            # Process file paths\n            file_paths = re.findall(r'RAG_file_path=\"([^\"]+)\"', user_input)\n            for fp in file_paths:\n                try:\n                    if not os.path.exists(fp):\n                        raise FileNotFoundError(f\"File not found: {fp}\")\n                        \n                    loader = PyPDFLoader(fp) if fp.endswith('.pdf') else TextLoader(fp)\n                    docs = loader.load()\n                    splits = text_splitter.split_documents(docs)\n                    \n                    # Add metadata\n                    for split in splits:\n                        split.metadata.update({\n                            \"source_type\": \"file\",\n                            \"source_path\": fp\n                        })\n                    \n                    vectorstore.add_documents(splits)\n                    print(f\"\\nAI: Added {len(splits)} chunks from {os.path.basename(fp)}\")\n                    user_input = user_input.replace(f'RAG_file_path=\"{fp}\"', '').strip()\n                except Exception as e:\n                    print(f\"\\nAI: Error processing {fp}: {str(e)}\")\n\n            # Process URLs\n            urls = re.findall(r'https?://\\S+', user_input)\n            for url in urls:\n                if process_web_content(url):\n                    user_input = user_input.replace(url, '').strip()\n\n            # Process remaining input\n            user_input = re.sub(r'\\s+', ' ', user_input).strip()\n            if not user_input:\n                continue\n                \n            response = chat_agent.invoke(\n                {\"input\": user_input},\n                {\"configurable\": {\"session_id\": SESSION_ID}}\n            )\n            print(f\"\\nAI: {response['response']}\")\n            \n        except Exception as e:\n            print(f\"Error: {str(e)}\")\n            continue\n    \n    return chat_agent\n\ndefined_llm(OPENAI_API_KEY, chat_prompt=chat_prompt)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T19:36:52.804739Z","iopub.execute_input":"2025-03-14T19:36:52.805123Z","iopub.status.idle":"2025-03-14T19:49:14.660464Z","shell.execute_reply.started":"2025-03-14T19:36:52.805094Z","shell.execute_reply":"2025-03-14T19:49:14.659306Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/langsmith/client.py:261: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Session ID: 044228bf-f8d8-4971-9996-74eee9e2f1b7\nMath Expert System - Type 'exit' to quit\nInput formats:\n- RAG_file_path=\"/path/to/file.pdf\" https://example.com Your question\n- Include math formulas using $...$ notation\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nYou:   20 bees are sitting on 20 daisies, one bee on each flower. The flowers are arranged in a ring. From time to time 2 bees simultaneously fly  in opposite directions (clockwise and counterclockwise), each to its neighboring flower. Can all bees gather on the same daisy at some point? Will your answer be the same for 19 daisies and 19 bees?\n"},{"name":"stdout","text":"\n🔍 Retrieved Context Preview:\n\n📄 Document 1:\n   Source: unknown\n   Content: Math Knowledge Base Initialized...\n\nAI: **Problem Analysis**\n\nThe problem involves bees moving around a circular arrangement of daisies. We need to determine if all bees can end up simultaneously on the same daisy through the provided movement rules. The bees move in such a way that could be modeled using permutations and cyclic properties.\n\n**Key Principles and Concepts**\n- Circular permutations\n- Symmetry in movements\n- Parity of permutations\n\n**Solution Steps**\n\n1. **Understanding the Movement:** Every movement involves two bees—one moving clockwise and the other counterclockwise. This means that if there are two bees moving in opposite directions, they effectively swap their positions while the other bees remain stationary.\n\n2. **Exploring Symmetry and Cycles:** The crucial aspect here is the parity (odd or even nature) of swapping positions.\n   - **For 20 daisies and 20 bees:** Each complete sequence where every bee has moved exactly once (i.e., every bee has moved to its neighboring position) can be viewed as a set of independent swaps. For each bee, to return to its original position (completing a cycle), it would require 20 swaps (since the bees move to neighboring positions, a bee initially at position 1 will move to position 2, then to 3, and so on until it reaches position 20 and back to 1).\n\n3. **Calculating Total Movements to Reconvene:**\n   - Each bee can complete a full cycle around the daisies and return to its starting position in 20 moves, thus the entire system returns to its original configuration every 20 moves. This is a symmetry where the number of bees equals the number of daisies.\n   - To all meet at a single daisy, the problem translates to seeing if there is a convergence point faster than or indifferent to the cycle rate. With 20 bees and 20 daisies, and since each bee moves systematically in a fixed direction, no converging single unique point other than the starting configuration appears feasible within the allowed movement rules. \n\n4. **Generalization and the Case of 19 Daisies and 19 Bees:**\n   - Similarly, with 19 daisies and 19 bees, the returning cycle is 19 steps. But here, the situation slightly changes due to the properties of prime numbers and circular permutations. With an odd number of positions (19), and systematic swap movements, the bees will undergo a cycle that might not synchronize immediately at the starting configuration but will eventually cover all positions, including potential meeting points. However, the challenge remains in the divergent directions, making convergence in one daisy simultaneously unlikely under given rules.\n\n5. **Final Verification with Basic Examples:**\n   - Trying smaller cases like 4 bees and 4 daisies or 3 bees and 3 daisies may help visualize why simultaneous convergence at a single point does not happen just through the neighboring swaps.\n\n**Final Answer**\n\nBased on the movement rules and analysis:\n- For 20 bees on 20 daisies, it is not feasible for all bees to gather on the same daisy at some point due to the parity and even distribution.\n- The answer remains the same for 19 bees on 19 daisies. The odd count does not inherently change the outcome; the bees still fail to converge all on a single daisy concurrently within the movement rules described.\n\n**Verification:**\n**Verification:**\n\nThe solution presented provides an in-depth analysis of a problem involving bees and daisies arranged in a circular pattern, with bees moving according to certain rules. Here's the verification based on logical and mathematical rigor:\n\n1. **Logic Check:**\n\n   - The solution intelligently uses concepts such as circular permutations, symmetry, and parity of permutations to analyze the problem.\n   - It critically examines the movement mechanism and correctly identifies that every movement forms a cyclic permutation, particularly focusing on the parity of such movements to deduce behavior over cycles.\n\n2. **Method and Formula Application:**\n\n   - The use of permutations, especially to determine the cycles needed for all bees to meet at a point, is accurately applied. The explanation that each bee completes a cycle back to its start after `n` moves (where `n` is the number of bees/daisies) under uniform systematic movement is correct.\n   - The insight into not achieving a single convergence point under the system's movement rules is logical and supported by the movement pattern described.\n\n3. **Step-by-Step Analysis:**\n\n   - The provided steps trace through a logical progression: understanding movement, examining symmetry and cycles, and then calculating the necessary movements for potential convergence.\n   - The conclusion that, due to the movement pattern, convergence at a single daisy is impractical with the given number of bees and daisies aligns with the properties of cyclic permutations in a symmetric arrangement.\n\n4. **Generalization and Case Application:**\n\n   - The solution's exploration of both even (e.g., 20) and odd (e.g., 19) numbers of bees/daisies and the reasoning about how these situations adjust the cycles are fundamental in understanding the problem at a broader scale.\n   - The application to smaller cases as a means of verification simplifies understanding and helps validate the overarching conclusions about more complex setups.\n\n5. **Error Checking and Correction:**\n\n   - There are no explicit mistakes or flawed calculations found within the explanation. The mathematical principles and logical deductions are sound and appropriately applied to the problem's specifics.\n\n**Final Conclusion:**\n\nBased on the detailed scrutiny of each component of the solution and considering the applied mathematical concepts and logical explanations are all correctly utilized and reasoned, the solution is **VERIFIED**.\n\n**Reason for Verification:**\n- The problem has been broken down logically, and appropriate mathematical concepts have been applied correctly to analyze the movement of bees around daisies.\n- Each step of the solution follows logically from the previous one, building a strong inference that within the given rules, convergence on a single daisy by all bees is not possible.\n- The thorough investigation into different scenarios (both odd and even numbers of daisies and bees) ensures that the conclusion is robust across similar cases.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-0560cfe6086b>\u001b[0m in \u001b[0;36m<cell line: 288>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mchat_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m \u001b[0mdefined_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOPENAI_API_KEY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchat_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchat_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-0560cfe6086b>\u001b[0m in \u001b[0;36mdefined_llm\u001b[0;34m(OPENAI_API_KEY, chat_prompt)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nYou: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'exit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'quit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Goodbye!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"],"ename":"KeyboardInterrupt","evalue":"Interrupted by user","output_type":"error"}],"execution_count":5}]}